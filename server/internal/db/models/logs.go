// Code generated by SQLBoiler 4.16.2 (https://github.com/volatiletech/sqlboiler). DO NOT EDIT.
// This file is meant to be re-generated in place and/or deleted at any time.

package models

import (
	"context"
	"database/sql"
	"fmt"
	"reflect"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/friendsofgo/errors"
	"github.com/volatiletech/null/v8"
	"github.com/volatiletech/sqlboiler/v4/boil"
	"github.com/volatiletech/sqlboiler/v4/queries"
	"github.com/volatiletech/sqlboiler/v4/queries/qm"
	"github.com/volatiletech/sqlboiler/v4/queries/qmhelper"
	"github.com/volatiletech/strmangle"
)

// Log is an object representing the database table.
type Log struct {
	ID        int64       `boil:"id" json:"id" toml:"id" yaml:"id"`
	Client    string      `boil:"client" json:"client" toml:"client" yaml:"client"`
	Level     string      `boil:"level" json:"level" toml:"level" yaml:"level"`
	Timestamp null.Time   `boil:"timestamp" json:"timestamp,omitempty" toml:"timestamp" yaml:"timestamp,omitempty"`
	Message   null.String `boil:"message" json:"message,omitempty" toml:"message" yaml:"message,omitempty"`
	Label     null.String `boil:"label" json:"label,omitempty" toml:"label" yaml:"label,omitempty"`

	R *logR `boil:"-" json:"-" toml:"-" yaml:"-"`
	L logL  `boil:"-" json:"-" toml:"-" yaml:"-"`
}

var LogColumns = struct {
	ID        string
	Client    string
	Level     string
	Timestamp string
	Message   string
	Label     string
}{
	ID:        "id",
	Client:    "client",
	Level:     "level",
	Timestamp: "timestamp",
	Message:   "message",
	Label:     "label",
}

var LogTableColumns = struct {
	ID        string
	Client    string
	Level     string
	Timestamp string
	Message   string
	Label     string
}{
	ID:        "logs.id",
	Client:    "logs.client",
	Level:     "logs.level",
	Timestamp: "logs.timestamp",
	Message:   "logs.message",
	Label:     "logs.label",
}

// Generated where

type whereHelperint64 struct{ field string }

func (w whereHelperint64) EQ(x int64) qm.QueryMod  { return qmhelper.Where(w.field, qmhelper.EQ, x) }
func (w whereHelperint64) NEQ(x int64) qm.QueryMod { return qmhelper.Where(w.field, qmhelper.NEQ, x) }
func (w whereHelperint64) LT(x int64) qm.QueryMod  { return qmhelper.Where(w.field, qmhelper.LT, x) }
func (w whereHelperint64) LTE(x int64) qm.QueryMod { return qmhelper.Where(w.field, qmhelper.LTE, x) }
func (w whereHelperint64) GT(x int64) qm.QueryMod  { return qmhelper.Where(w.field, qmhelper.GT, x) }
func (w whereHelperint64) GTE(x int64) qm.QueryMod { return qmhelper.Where(w.field, qmhelper.GTE, x) }
func (w whereHelperint64) IN(slice []int64) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereIn(fmt.Sprintf("%s IN ?", w.field), values...)
}
func (w whereHelperint64) NIN(slice []int64) qm.QueryMod {
	values := make([]interface{}, 0, len(slice))
	for _, value := range slice {
		values = append(values, value)
	}
	return qm.WhereNotIn(fmt.Sprintf("%s NOT IN ?", w.field), values...)
}

type whereHelpernull_Time struct{ field string }

func (w whereHelpernull_Time) EQ(x null.Time) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, false, x)
}
func (w whereHelpernull_Time) NEQ(x null.Time) qm.QueryMod {
	return qmhelper.WhereNullEQ(w.field, true, x)
}
func (w whereHelpernull_Time) LT(x null.Time) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LT, x)
}
func (w whereHelpernull_Time) LTE(x null.Time) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.LTE, x)
}
func (w whereHelpernull_Time) GT(x null.Time) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GT, x)
}
func (w whereHelpernull_Time) GTE(x null.Time) qm.QueryMod {
	return qmhelper.Where(w.field, qmhelper.GTE, x)
}

func (w whereHelpernull_Time) IsNull() qm.QueryMod    { return qmhelper.WhereIsNull(w.field) }
func (w whereHelpernull_Time) IsNotNull() qm.QueryMod { return qmhelper.WhereIsNotNull(w.field) }

var LogWhere = struct {
	ID        whereHelperint64
	Client    whereHelperstring
	Level     whereHelperstring
	Timestamp whereHelpernull_Time
	Message   whereHelpernull_String
	Label     whereHelpernull_String
}{
	ID:        whereHelperint64{field: "\"logs\".\"id\""},
	Client:    whereHelperstring{field: "\"logs\".\"client\""},
	Level:     whereHelperstring{field: "\"logs\".\"level\""},
	Timestamp: whereHelpernull_Time{field: "\"logs\".\"timestamp\""},
	Message:   whereHelpernull_String{field: "\"logs\".\"message\""},
	Label:     whereHelpernull_String{field: "\"logs\".\"label\""},
}

// LogRels is where relationship names are stored.
var LogRels = struct {
	LogClient string
}{
	LogClient: "LogClient",
}

// logR is where relationships are stored.
type logR struct {
	LogClient *Client `boil:"LogClient" json:"LogClient" toml:"LogClient" yaml:"LogClient"`
}

// NewStruct creates a new relationship struct
func (*logR) NewStruct() *logR {
	return &logR{}
}

func (r *logR) GetLogClient() *Client {
	if r == nil {
		return nil
	}
	return r.LogClient
}

// logL is where Load methods for each relationship are stored.
type logL struct{}

var (
	logAllColumns            = []string{"id", "client", "level", "timestamp", "message", "label"}
	logColumnsWithoutDefault = []string{"client", "level"}
	logColumnsWithDefault    = []string{"id", "timestamp", "message", "label"}
	logPrimaryKeyColumns     = []string{"id"}
	logGeneratedColumns      = []string{}
)

type (
	// LogSlice is an alias for a slice of pointers to Log.
	// This should almost always be used instead of []Log.
	LogSlice []*Log
	// LogHook is the signature for custom Log hook methods
	LogHook func(context.Context, boil.ContextExecutor, *Log) error

	logQuery struct {
		*queries.Query
	}
)

// Cache for insert, update and upsert
var (
	logType                 = reflect.TypeOf(&Log{})
	logMapping              = queries.MakeStructMapping(logType)
	logPrimaryKeyMapping, _ = queries.BindMapping(logType, logMapping, logPrimaryKeyColumns)
	logInsertCacheMut       sync.RWMutex
	logInsertCache          = make(map[string]insertCache)
	logUpdateCacheMut       sync.RWMutex
	logUpdateCache          = make(map[string]updateCache)
	logUpsertCacheMut       sync.RWMutex
	logUpsertCache          = make(map[string]insertCache)
)

var (
	// Force time package dependency for automated UpdatedAt/CreatedAt.
	_ = time.Second
	// Force qmhelper dependency for where clause generation (which doesn't
	// always happen)
	_ = qmhelper.Where
)

var logAfterSelectMu sync.Mutex
var logAfterSelectHooks []LogHook

var logBeforeInsertMu sync.Mutex
var logBeforeInsertHooks []LogHook
var logAfterInsertMu sync.Mutex
var logAfterInsertHooks []LogHook

var logBeforeUpdateMu sync.Mutex
var logBeforeUpdateHooks []LogHook
var logAfterUpdateMu sync.Mutex
var logAfterUpdateHooks []LogHook

var logBeforeDeleteMu sync.Mutex
var logBeforeDeleteHooks []LogHook
var logAfterDeleteMu sync.Mutex
var logAfterDeleteHooks []LogHook

var logBeforeUpsertMu sync.Mutex
var logBeforeUpsertHooks []LogHook
var logAfterUpsertMu sync.Mutex
var logAfterUpsertHooks []LogHook

// doAfterSelectHooks executes all "after Select" hooks.
func (o *Log) doAfterSelectHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range logAfterSelectHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doBeforeInsertHooks executes all "before insert" hooks.
func (o *Log) doBeforeInsertHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range logBeforeInsertHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doAfterInsertHooks executes all "after Insert" hooks.
func (o *Log) doAfterInsertHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range logAfterInsertHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doBeforeUpdateHooks executes all "before Update" hooks.
func (o *Log) doBeforeUpdateHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range logBeforeUpdateHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doAfterUpdateHooks executes all "after Update" hooks.
func (o *Log) doAfterUpdateHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range logAfterUpdateHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doBeforeDeleteHooks executes all "before Delete" hooks.
func (o *Log) doBeforeDeleteHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range logBeforeDeleteHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doAfterDeleteHooks executes all "after Delete" hooks.
func (o *Log) doAfterDeleteHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range logAfterDeleteHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doBeforeUpsertHooks executes all "before Upsert" hooks.
func (o *Log) doBeforeUpsertHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range logBeforeUpsertHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// doAfterUpsertHooks executes all "after Upsert" hooks.
func (o *Log) doAfterUpsertHooks(ctx context.Context, exec boil.ContextExecutor) (err error) {
	if boil.HooksAreSkipped(ctx) {
		return nil
	}

	for _, hook := range logAfterUpsertHooks {
		if err := hook(ctx, exec, o); err != nil {
			return err
		}
	}

	return nil
}

// AddLogHook registers your hook function for all future operations.
func AddLogHook(hookPoint boil.HookPoint, logHook LogHook) {
	switch hookPoint {
	case boil.AfterSelectHook:
		logAfterSelectMu.Lock()
		logAfterSelectHooks = append(logAfterSelectHooks, logHook)
		logAfterSelectMu.Unlock()
	case boil.BeforeInsertHook:
		logBeforeInsertMu.Lock()
		logBeforeInsertHooks = append(logBeforeInsertHooks, logHook)
		logBeforeInsertMu.Unlock()
	case boil.AfterInsertHook:
		logAfterInsertMu.Lock()
		logAfterInsertHooks = append(logAfterInsertHooks, logHook)
		logAfterInsertMu.Unlock()
	case boil.BeforeUpdateHook:
		logBeforeUpdateMu.Lock()
		logBeforeUpdateHooks = append(logBeforeUpdateHooks, logHook)
		logBeforeUpdateMu.Unlock()
	case boil.AfterUpdateHook:
		logAfterUpdateMu.Lock()
		logAfterUpdateHooks = append(logAfterUpdateHooks, logHook)
		logAfterUpdateMu.Unlock()
	case boil.BeforeDeleteHook:
		logBeforeDeleteMu.Lock()
		logBeforeDeleteHooks = append(logBeforeDeleteHooks, logHook)
		logBeforeDeleteMu.Unlock()
	case boil.AfterDeleteHook:
		logAfterDeleteMu.Lock()
		logAfterDeleteHooks = append(logAfterDeleteHooks, logHook)
		logAfterDeleteMu.Unlock()
	case boil.BeforeUpsertHook:
		logBeforeUpsertMu.Lock()
		logBeforeUpsertHooks = append(logBeforeUpsertHooks, logHook)
		logBeforeUpsertMu.Unlock()
	case boil.AfterUpsertHook:
		logAfterUpsertMu.Lock()
		logAfterUpsertHooks = append(logAfterUpsertHooks, logHook)
		logAfterUpsertMu.Unlock()
	}
}

// One returns a single log record from the query.
func (q logQuery) One(ctx context.Context, exec boil.ContextExecutor) (*Log, error) {
	o := &Log{}

	queries.SetLimit(q.Query, 1)

	err := q.Bind(ctx, exec, o)
	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			return nil, sql.ErrNoRows
		}
		return nil, errors.Wrap(err, "models: failed to execute a one query for logs")
	}

	if err := o.doAfterSelectHooks(ctx, exec); err != nil {
		return o, err
	}

	return o, nil
}

// All returns all Log records from the query.
func (q logQuery) All(ctx context.Context, exec boil.ContextExecutor) (LogSlice, error) {
	var o []*Log

	err := q.Bind(ctx, exec, &o)
	if err != nil {
		return nil, errors.Wrap(err, "models: failed to assign all query results to Log slice")
	}

	if len(logAfterSelectHooks) != 0 {
		for _, obj := range o {
			if err := obj.doAfterSelectHooks(ctx, exec); err != nil {
				return o, err
			}
		}
	}

	return o, nil
}

// Count returns the count of all Log records in the query.
func (q logQuery) Count(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)

	err := q.Query.QueryRowContext(ctx, exec).Scan(&count)
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to count logs rows")
	}

	return count, nil
}

// Exists checks if the row exists in the table.
func (q logQuery) Exists(ctx context.Context, exec boil.ContextExecutor) (bool, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)
	queries.SetLimit(q.Query, 1)

	err := q.Query.QueryRowContext(ctx, exec).Scan(&count)
	if err != nil {
		return false, errors.Wrap(err, "models: failed to check if logs exists")
	}

	return count > 0, nil
}

// LogClient pointed to by the foreign key.
func (o *Log) LogClient(mods ...qm.QueryMod) clientQuery {
	queryMods := []qm.QueryMod{
		qm.Where("\"id\" = ?", o.Client),
	}

	queryMods = append(queryMods, mods...)

	return Clients(queryMods...)
}

// LoadLogClient allows an eager lookup of values, cached into the
// loaded structs of the objects. This is for an N-1 relationship.
func (logL) LoadLogClient(ctx context.Context, e boil.ContextExecutor, singular bool, maybeLog interface{}, mods queries.Applicator) error {
	var slice []*Log
	var object *Log

	if singular {
		var ok bool
		object, ok = maybeLog.(*Log)
		if !ok {
			object = new(Log)
			ok = queries.SetFromEmbeddedStruct(&object, &maybeLog)
			if !ok {
				return errors.New(fmt.Sprintf("failed to set %T from embedded struct %T", object, maybeLog))
			}
		}
	} else {
		s, ok := maybeLog.(*[]*Log)
		if ok {
			slice = *s
		} else {
			ok = queries.SetFromEmbeddedStruct(&slice, maybeLog)
			if !ok {
				return errors.New(fmt.Sprintf("failed to set %T from embedded struct %T", slice, maybeLog))
			}
		}
	}

	args := make(map[interface{}]struct{})
	if singular {
		if object.R == nil {
			object.R = &logR{}
		}
		args[object.Client] = struct{}{}

	} else {
		for _, obj := range slice {
			if obj.R == nil {
				obj.R = &logR{}
			}

			args[obj.Client] = struct{}{}

		}
	}

	if len(args) == 0 {
		return nil
	}

	argsSlice := make([]interface{}, len(args))
	i := 0
	for arg := range args {
		argsSlice[i] = arg
		i++
	}

	query := NewQuery(
		qm.From(`clients`),
		qm.WhereIn(`clients.id in ?`, argsSlice...),
	)
	if mods != nil {
		mods.Apply(query)
	}

	results, err := query.QueryContext(ctx, e)
	if err != nil {
		return errors.Wrap(err, "failed to eager load Client")
	}

	var resultSlice []*Client
	if err = queries.Bind(results, &resultSlice); err != nil {
		return errors.Wrap(err, "failed to bind eager loaded slice Client")
	}

	if err = results.Close(); err != nil {
		return errors.Wrap(err, "failed to close results of eager load for clients")
	}
	if err = results.Err(); err != nil {
		return errors.Wrap(err, "error occurred during iteration of eager loaded relations for clients")
	}

	if len(clientAfterSelectHooks) != 0 {
		for _, obj := range resultSlice {
			if err := obj.doAfterSelectHooks(ctx, e); err != nil {
				return err
			}
		}
	}

	if len(resultSlice) == 0 {
		return nil
	}

	if singular {
		foreign := resultSlice[0]
		object.R.LogClient = foreign
		if foreign.R == nil {
			foreign.R = &clientR{}
		}
		foreign.R.Logs = append(foreign.R.Logs, object)
		return nil
	}

	for _, local := range slice {
		for _, foreign := range resultSlice {
			if local.Client == foreign.ID {
				local.R.LogClient = foreign
				if foreign.R == nil {
					foreign.R = &clientR{}
				}
				foreign.R.Logs = append(foreign.R.Logs, local)
				break
			}
		}
	}

	return nil
}

// SetLogClient of the log to the related item.
// Sets o.R.LogClient to related.
// Adds o to related.R.Logs.
func (o *Log) SetLogClient(ctx context.Context, exec boil.ContextExecutor, insert bool, related *Client) error {
	var err error
	if insert {
		if err = related.Insert(ctx, exec, boil.Infer()); err != nil {
			return errors.Wrap(err, "failed to insert into foreign table")
		}
	}

	updateQuery := fmt.Sprintf(
		"UPDATE \"logs\" SET %s WHERE %s",
		strmangle.SetParamNames("\"", "\"", 1, []string{"client"}),
		strmangle.WhereClause("\"", "\"", 2, logPrimaryKeyColumns),
	)
	values := []interface{}{related.ID, o.ID}

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, updateQuery)
		fmt.Fprintln(writer, values)
	}
	if _, err = exec.ExecContext(ctx, updateQuery, values...); err != nil {
		return errors.Wrap(err, "failed to update local table")
	}

	o.Client = related.ID
	if o.R == nil {
		o.R = &logR{
			LogClient: related,
		}
	} else {
		o.R.LogClient = related
	}

	if related.R == nil {
		related.R = &clientR{
			Logs: LogSlice{o},
		}
	} else {
		related.R.Logs = append(related.R.Logs, o)
	}

	return nil
}

// Logs retrieves all the records using an executor.
func Logs(mods ...qm.QueryMod) logQuery {
	mods = append(mods, qm.From("\"logs\""))
	q := NewQuery(mods...)
	if len(queries.GetSelect(q)) == 0 {
		queries.SetSelect(q, []string{"\"logs\".*"})
	}

	return logQuery{q}
}

// FindLog retrieves a single record by ID with an executor.
// If selectCols is empty Find will return all columns.
func FindLog(ctx context.Context, exec boil.ContextExecutor, iD int64, selectCols ...string) (*Log, error) {
	logObj := &Log{}

	sel := "*"
	if len(selectCols) > 0 {
		sel = strings.Join(strmangle.IdentQuoteSlice(dialect.LQ, dialect.RQ, selectCols), ",")
	}
	query := fmt.Sprintf(
		"select %s from \"logs\" where \"id\"=$1", sel,
	)

	q := queries.Raw(query, iD)

	err := q.Bind(ctx, exec, logObj)
	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			return nil, sql.ErrNoRows
		}
		return nil, errors.Wrap(err, "models: unable to select from logs")
	}

	if err = logObj.doAfterSelectHooks(ctx, exec); err != nil {
		return logObj, err
	}

	return logObj, nil
}

// Insert a single record using an executor.
// See boil.Columns.InsertColumnSet documentation to understand column list inference for inserts.
func (o *Log) Insert(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) error {
	if o == nil {
		return errors.New("models: no logs provided for insertion")
	}

	var err error

	if err := o.doBeforeInsertHooks(ctx, exec); err != nil {
		return err
	}

	nzDefaults := queries.NonZeroDefaultSet(logColumnsWithDefault, o)

	key := makeCacheKey(columns, nzDefaults)
	logInsertCacheMut.RLock()
	cache, cached := logInsertCache[key]
	logInsertCacheMut.RUnlock()

	if !cached {
		wl, returnColumns := columns.InsertColumnSet(
			logAllColumns,
			logColumnsWithDefault,
			logColumnsWithoutDefault,
			nzDefaults,
		)

		cache.valueMapping, err = queries.BindMapping(logType, logMapping, wl)
		if err != nil {
			return err
		}
		cache.retMapping, err = queries.BindMapping(logType, logMapping, returnColumns)
		if err != nil {
			return err
		}
		if len(wl) != 0 {
			cache.query = fmt.Sprintf("INSERT INTO \"logs\" (\"%s\") %%sVALUES (%s)%%s", strings.Join(wl, "\",\""), strmangle.Placeholders(dialect.UseIndexPlaceholders, len(wl), 1, 1))
		} else {
			cache.query = "INSERT INTO \"logs\" %sDEFAULT VALUES%s"
		}

		var queryOutput, queryReturning string

		if len(cache.retMapping) != 0 {
			queryReturning = fmt.Sprintf(" RETURNING \"%s\"", strings.Join(returnColumns, "\",\""))
		}

		cache.query = fmt.Sprintf(cache.query, queryOutput, queryReturning)
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, vals)
	}

	if len(cache.retMapping) != 0 {
		err = exec.QueryRowContext(ctx, cache.query, vals...).Scan(queries.PtrsFromMapping(value, cache.retMapping)...)
	} else {
		_, err = exec.ExecContext(ctx, cache.query, vals...)
	}

	if err != nil {
		return errors.Wrap(err, "models: unable to insert into logs")
	}

	if !cached {
		logInsertCacheMut.Lock()
		logInsertCache[key] = cache
		logInsertCacheMut.Unlock()
	}

	return o.doAfterInsertHooks(ctx, exec)
}

// Update uses an executor to update the Log.
// See boil.Columns.UpdateColumnSet documentation to understand column list inference for updates.
// Update does not automatically update the record in case of default values. Use .Reload() to refresh the records.
func (o *Log) Update(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) (int64, error) {
	var err error
	if err = o.doBeforeUpdateHooks(ctx, exec); err != nil {
		return 0, err
	}
	key := makeCacheKey(columns, nil)
	logUpdateCacheMut.RLock()
	cache, cached := logUpdateCache[key]
	logUpdateCacheMut.RUnlock()

	if !cached {
		wl := columns.UpdateColumnSet(
			logAllColumns,
			logPrimaryKeyColumns,
		)

		if !columns.IsWhitelist() {
			wl = strmangle.SetComplement(wl, []string{"created_at"})
		}
		if len(wl) == 0 {
			return 0, errors.New("models: unable to update logs, could not build whitelist")
		}

		cache.query = fmt.Sprintf("UPDATE \"logs\" SET %s WHERE %s",
			strmangle.SetParamNames("\"", "\"", 1, wl),
			strmangle.WhereClause("\"", "\"", len(wl)+1, logPrimaryKeyColumns),
		)
		cache.valueMapping, err = queries.BindMapping(logType, logMapping, append(wl, logPrimaryKeyColumns...))
		if err != nil {
			return 0, err
		}
	}

	values := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), cache.valueMapping)

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, values)
	}
	var result sql.Result
	result, err = exec.ExecContext(ctx, cache.query, values...)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to update logs row")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to get rows affected by update for logs")
	}

	if !cached {
		logUpdateCacheMut.Lock()
		logUpdateCache[key] = cache
		logUpdateCacheMut.Unlock()
	}

	return rowsAff, o.doAfterUpdateHooks(ctx, exec)
}

// UpdateAll updates all rows with the specified column values.
func (q logQuery) UpdateAll(ctx context.Context, exec boil.ContextExecutor, cols M) (int64, error) {
	queries.SetUpdate(q.Query, cols)

	result, err := q.Query.ExecContext(ctx, exec)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to update all for logs")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to retrieve rows affected for logs")
	}

	return rowsAff, nil
}

// UpdateAll updates all rows with the specified column values, using an executor.
func (o LogSlice) UpdateAll(ctx context.Context, exec boil.ContextExecutor, cols M) (int64, error) {
	ln := int64(len(o))
	if ln == 0 {
		return 0, nil
	}

	if len(cols) == 0 {
		return 0, errors.New("models: update all requires at least one column argument")
	}

	colNames := make([]string, len(cols))
	args := make([]interface{}, len(cols))

	i := 0
	for name, value := range cols {
		colNames[i] = name
		args[i] = value
		i++
	}

	// Append all of the primary key values for each column
	for _, obj := range o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), logPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := fmt.Sprintf("UPDATE \"logs\" SET %s WHERE %s",
		strmangle.SetParamNames("\"", "\"", 1, colNames),
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), len(colNames)+1, logPrimaryKeyColumns, len(o)))

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, args...)
	}
	result, err := exec.ExecContext(ctx, sql, args...)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to update all in log slice")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to retrieve rows affected all in update all log")
	}
	return rowsAff, nil
}

// Upsert attempts an insert using an executor, and does an update or ignore on conflict.
// See boil.Columns documentation for how to properly use updateColumns and insertColumns.
func (o *Log) Upsert(ctx context.Context, exec boil.ContextExecutor, updateOnConflict bool, conflictColumns []string, updateColumns, insertColumns boil.Columns) error {
	if o == nil {
		return errors.New("models: no logs provided for upsert")
	}

	if err := o.doBeforeUpsertHooks(ctx, exec); err != nil {
		return err
	}

	nzDefaults := queries.NonZeroDefaultSet(logColumnsWithDefault, o)

	// Build cache key in-line uglily - mysql vs psql problems
	buf := strmangle.GetBuffer()
	if updateOnConflict {
		buf.WriteByte('t')
	} else {
		buf.WriteByte('f')
	}
	buf.WriteByte('.')
	for _, c := range conflictColumns {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	buf.WriteString(strconv.Itoa(updateColumns.Kind))
	for _, c := range updateColumns.Cols {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	buf.WriteString(strconv.Itoa(insertColumns.Kind))
	for _, c := range insertColumns.Cols {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	for _, c := range nzDefaults {
		buf.WriteString(c)
	}
	key := buf.String()
	strmangle.PutBuffer(buf)

	logUpsertCacheMut.RLock()
	cache, cached := logUpsertCache[key]
	logUpsertCacheMut.RUnlock()

	var err error

	if !cached {
		insert, ret := insertColumns.InsertColumnSet(
			logAllColumns,
			logColumnsWithDefault,
			logColumnsWithoutDefault,
			nzDefaults,
		)

		update := updateColumns.UpdateColumnSet(
			logAllColumns,
			logPrimaryKeyColumns,
		)

		if updateOnConflict && len(update) == 0 {
			return errors.New("models: unable to upsert logs, could not build update column list")
		}

		conflict := conflictColumns
		if len(conflict) == 0 {
			conflict = make([]string, len(logPrimaryKeyColumns))
			copy(conflict, logPrimaryKeyColumns)
		}
		cache.query = buildUpsertQueryPostgres(dialect, "\"logs\"", updateOnConflict, ret, update, conflict, insert)

		cache.valueMapping, err = queries.BindMapping(logType, logMapping, insert)
		if err != nil {
			return err
		}
		if len(ret) != 0 {
			cache.retMapping, err = queries.BindMapping(logType, logMapping, ret)
			if err != nil {
				return err
			}
		}
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)
	var returns []interface{}
	if len(cache.retMapping) != 0 {
		returns = queries.PtrsFromMapping(value, cache.retMapping)
	}

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, vals)
	}
	if len(cache.retMapping) != 0 {
		err = exec.QueryRowContext(ctx, cache.query, vals...).Scan(returns...)
		if errors.Is(err, sql.ErrNoRows) {
			err = nil // Postgres doesn't return anything when there's no update
		}
	} else {
		_, err = exec.ExecContext(ctx, cache.query, vals...)
	}
	if err != nil {
		return errors.Wrap(err, "models: unable to upsert logs")
	}

	if !cached {
		logUpsertCacheMut.Lock()
		logUpsertCache[key] = cache
		logUpsertCacheMut.Unlock()
	}

	return o.doAfterUpsertHooks(ctx, exec)
}

// Delete deletes a single Log record with an executor.
// Delete will match against the primary key column to find the record to delete.
func (o *Log) Delete(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	if o == nil {
		return 0, errors.New("models: no Log provided for delete")
	}

	if err := o.doBeforeDeleteHooks(ctx, exec); err != nil {
		return 0, err
	}

	args := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), logPrimaryKeyMapping)
	sql := "DELETE FROM \"logs\" WHERE \"id\"=$1"

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, args...)
	}
	result, err := exec.ExecContext(ctx, sql, args...)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to delete from logs")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to get rows affected by delete for logs")
	}

	if err := o.doAfterDeleteHooks(ctx, exec); err != nil {
		return 0, err
	}

	return rowsAff, nil
}

// DeleteAll deletes all matching rows.
func (q logQuery) DeleteAll(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	if q.Query == nil {
		return 0, errors.New("models: no logQuery provided for delete all")
	}

	queries.SetDelete(q.Query)

	result, err := q.Query.ExecContext(ctx, exec)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to delete all from logs")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to get rows affected by deleteall for logs")
	}

	return rowsAff, nil
}

// DeleteAll deletes all rows in the slice, using an executor.
func (o LogSlice) DeleteAll(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	if len(o) == 0 {
		return 0, nil
	}

	if len(logBeforeDeleteHooks) != 0 {
		for _, obj := range o {
			if err := obj.doBeforeDeleteHooks(ctx, exec); err != nil {
				return 0, err
			}
		}
	}

	var args []interface{}
	for _, obj := range o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), logPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := "DELETE FROM \"logs\" WHERE " +
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 1, logPrimaryKeyColumns, len(o))

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, args)
	}
	result, err := exec.ExecContext(ctx, sql, args...)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to delete all from log slice")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to get rows affected by deleteall for logs")
	}

	if len(logAfterDeleteHooks) != 0 {
		for _, obj := range o {
			if err := obj.doAfterDeleteHooks(ctx, exec); err != nil {
				return 0, err
			}
		}
	}

	return rowsAff, nil
}

// Reload refetches the object from the database
// using the primary keys with an executor.
func (o *Log) Reload(ctx context.Context, exec boil.ContextExecutor) error {
	ret, err := FindLog(ctx, exec, o.ID)
	if err != nil {
		return err
	}

	*o = *ret
	return nil
}

// ReloadAll refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
func (o *LogSlice) ReloadAll(ctx context.Context, exec boil.ContextExecutor) error {
	if o == nil || len(*o) == 0 {
		return nil
	}

	slice := LogSlice{}
	var args []interface{}
	for _, obj := range *o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), logPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := "SELECT \"logs\".* FROM \"logs\" WHERE " +
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 1, logPrimaryKeyColumns, len(*o))

	q := queries.Raw(sql, args...)

	err := q.Bind(ctx, exec, &slice)
	if err != nil {
		return errors.Wrap(err, "models: unable to reload all in LogSlice")
	}

	*o = slice

	return nil
}

// LogExists checks if the Log row exists.
func LogExists(ctx context.Context, exec boil.ContextExecutor, iD int64) (bool, error) {
	var exists bool
	sql := "select exists(select 1 from \"logs\" where \"id\"=$1 limit 1)"

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, iD)
	}
	row := exec.QueryRowContext(ctx, sql, iD)

	err := row.Scan(&exists)
	if err != nil {
		return false, errors.Wrap(err, "models: unable to check if logs exists")
	}

	return exists, nil
}

// Exists checks if the Log row exists.
func (o *Log) Exists(ctx context.Context, exec boil.ContextExecutor) (bool, error) {
	return LogExists(ctx, exec, o.ID)
}

// /////////////////////////////// BEGIN EXTENSIONS /////////////////////////////////
// Expose table columns
var (
	LogAllColumns            = logAllColumns
	LogColumnsWithoutDefault = logColumnsWithoutDefault
	LogColumnsWithDefault    = logColumnsWithDefault
	LogPrimaryKeyColumns     = logPrimaryKeyColumns
	LogGeneratedColumns      = logGeneratedColumns
)

// GetID get ID from model object
func (o *Log) GetID() int64 {
	return o.ID
}

// GetIDs extract IDs from model objects
func (s LogSlice) GetIDs() []int64 {
	result := make([]int64, len(s))
	for i := range s {
		result[i] = s[i].ID
	}
	return result
}

// GetIntfIDs extract IDs from model objects as interface slice
func (s LogSlice) GetIntfIDs() []interface{} {
	result := make([]interface{}, len(s))
	for i := range s {
		result[i] = s[i].ID
	}
	return result
}

// ToIDMap convert a slice of model objects to a map with ID as key
func (s LogSlice) ToIDMap() map[int64]*Log {
	result := make(map[int64]*Log, len(s))
	for _, o := range s {
		result[o.ID] = o
	}
	return result
}

// ToUniqueItems construct a slice of unique items from the given slice
func (s LogSlice) ToUniqueItems() LogSlice {
	result := make(LogSlice, 0, len(s))
	mapChk := make(map[int64]struct{}, len(s))
	for i := len(s) - 1; i >= 0; i-- {
		o := s[i]
		if _, ok := mapChk[o.ID]; !ok {
			mapChk[o.ID] = struct{}{}
			result = append(result, o)
		}
	}
	return result
}

// FindItemByID find item by ID in the slice
func (s LogSlice) FindItemByID(id int64) *Log {
	for _, o := range s {
		if o.ID == id {
			return o
		}
	}
	return nil
}

// FindMissingItemIDs find all item IDs that are not in the list
// NOTE: the input ID slice should contain unique values
func (s LogSlice) FindMissingItemIDs(expectedIDs []int64) []int64 {
	if len(s) == 0 {
		return expectedIDs
	}
	result := []int64{}
	mapChk := s.ToIDMap()
	for _, id := range expectedIDs {
		if _, ok := mapChk[id]; !ok {
			result = append(result, id)
		}
	}
	return result
}

// InsertAll inserts all rows with the specified column values, using an executor.
// IMPORTANT: this will calculate the widest columns from all items in the slice, be careful if you want to use default column values
func (o LogSlice) InsertAll(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) (int64, error) {
	if len(o) == 0 {
		return 0, nil
	}

	// Calculate the widest columns from all rows need to insert
	wlCols := make(map[string]struct{}, 10)
	for _, row := range o {
		wl, _ := columns.InsertColumnSet(
			logAllColumns,
			logColumnsWithDefault,
			logColumnsWithoutDefault,
			queries.NonZeroDefaultSet(logColumnsWithDefault, row),
		)
		for _, col := range wl {
			wlCols[col] = struct{}{}
		}
	}
	wl := make([]string, 0, len(wlCols))
	for _, col := range logAllColumns {
		if _, ok := wlCols[col]; ok {
			wl = append(wl, col)
		}
	}

	var sql string
	vals := []interface{}{}
	for i, row := range o {

		if err := row.doBeforeInsertHooks(ctx, exec); err != nil {
			return 0, err
		}

		if i == 0 {
			sql = "INSERT INTO \"logs\" " + "(\"" + strings.Join(wl, "\",\"") + "\")" + " VALUES "
		}
		sql += strmangle.Placeholders(dialect.UseIndexPlaceholders, len(wl), len(vals)+1, len(wl))
		if i != len(o)-1 {
			sql += ","
		}
		valMapping, err := queries.BindMapping(logType, logMapping, wl)
		if err != nil {
			return 0, err
		}

		value := reflect.Indirect(reflect.ValueOf(row))
		vals = append(vals, queries.ValuesFromMapping(value, valMapping)...)
	}

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, vals)
	}

	result, err := exec.ExecContext(ctx, sql, vals...)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to insert all from log slice")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to get rows affected by insertall for logs")
	}

	if len(logAfterInsertHooks) != 0 {
		for _, obj := range o {
			if err := obj.doAfterInsertHooks(ctx, exec); err != nil {
				return 0, err
			}
		}
	}

	return rowsAff, nil
}

// InsertIgnoreAll inserts all rows with ignoring the existing ones having the same primary key values.
// NOTE: This function calls UpsertAll() with updateOnConflict=false and conflictColumns=<primary key columns>
// IMPORTANT: this will calculate the widest columns from all items in the slice, be careful if you want to use default column values
// IMPORTANT: if the table has `id` column of auto-increment type, this may not work as expected
func (o LogSlice) InsertIgnoreAll(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) (int64, error) {
	return o.UpsertAll(ctx, exec, false, logPrimaryKeyColumns, boil.None(), columns)
}

// UpsertAll inserts or updates all rows
// Currently it doesn't support "NoContext" and "NoRowsAffected"
// IMPORTANT: this will calculate the widest columns from all items in the slice, be careful if you want to use default column values
// IMPORTANT: if the table has `id` column of auto-increment type, this may not work as expected
func (o LogSlice) UpsertAll(ctx context.Context, exec boil.ContextExecutor, updateOnConflict bool, conflictColumns []string, updateColumns, insertColumns boil.Columns) (int64, error) {
	if len(o) == 0 {
		return 0, nil
	}

	// Calculate the widest columns from all rows need to upsert
	insertCols := make(map[string]struct{}, 10)
	for _, row := range o {
		insert, _ := insertColumns.InsertColumnSet(
			logAllColumns,
			logColumnsWithDefault,
			logColumnsWithoutDefault,
			queries.NonZeroDefaultSet(logColumnsWithDefault, row),
		)
		for _, col := range insert {
			insertCols[col] = struct{}{}
		}
	}
	insert := make([]string, 0, len(insertCols))
	for _, col := range logAllColumns {
		if _, ok := insertCols[col]; ok {
			insert = append(insert, col)
		}
	}

	update := updateColumns.UpdateColumnSet(
		logAllColumns,
		logPrimaryKeyColumns,
	)

	if updateOnConflict && len(update) == 0 {
		return 0, errors.New("models: unable to upsert logs, could not build update column list")
	}

	conflict := conflictColumns
	if len(conflict) == 0 {
		conflict = make([]string, len(logPrimaryKeyColumns))
		copy(conflict, logPrimaryKeyColumns)
	}

	buf := strmangle.GetBuffer()
	defer strmangle.PutBuffer(buf)

	columns := "DEFAULT VALUES"
	if len(insert) != 0 {
		columns = fmt.Sprintf("(%s) VALUES %s",
			strings.Join(insert, ", "),
			strmangle.Placeholders(dialect.UseIndexPlaceholders, len(insert)*len(o), 1, len(insert)),
		)
	}

	fmt.Fprintf(
		buf,
		"INSERT INTO %s %s ON CONFLICT ",
		"\"logs\"",
		columns,
	)

	if !updateOnConflict || len(update) == 0 {
		buf.WriteString("DO NOTHING")
	} else {
		buf.WriteByte('(')
		buf.WriteString(strings.Join(conflict, ", "))
		buf.WriteString(") DO UPDATE SET ")

		for i, v := range update {
			if i != 0 {
				buf.WriteByte(',')
			}
			quoted := strmangle.IdentQuote(dialect.LQ, dialect.RQ, v)
			buf.WriteString(quoted)
			buf.WriteString(" = EXCLUDED.")
			buf.WriteString(quoted)
		}
	}

	query := buf.String()
	valueMapping, err := queries.BindMapping(logType, logMapping, insert)
	if err != nil {
		return 0, err
	}

	var vals []interface{}
	for _, row := range o {

		if err := row.doBeforeUpsertHooks(ctx, exec); err != nil {
			return 0, err
		}

		value := reflect.Indirect(reflect.ValueOf(row))
		vals = append(vals, queries.ValuesFromMapping(value, valueMapping)...)
	}

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, query)
		fmt.Fprintln(writer, vals)
	}

	result, err := exec.ExecContext(ctx, query, vals...)
	if err != nil {
		return 0, errors.Wrap(err, "models: unable to upsert for logs")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to get rows affected by upsert for logs")
	}

	if len(logAfterUpsertHooks) != 0 {
		for _, obj := range o {
			if err := obj.doAfterUpsertHooks(ctx, exec); err != nil {
				return 0, err
			}
		}
	}

	return rowsAff, nil
}

// DeleteAllByPage delete all Log records from the slice.
// This function deletes data by pages to avoid exceeding Postgres limitation (max parameters: 65535)
func (s LogSlice) DeleteAllByPage(ctx context.Context, exec boil.ContextExecutor, limits ...int) (int64, error) {
	length := len(s)
	if length == 0 {
		return 0, nil
	}

	// max number of parameters = 65535
	chunkSize := DefaultPageSize
	if len(limits) > 0 && limits[0] > 0 && limits[0] <= MaxPageSize {
		chunkSize = limits[0]
	}
	if length <= chunkSize {
		return s.DeleteAll(ctx, exec)
	}

	rowsAffected := int64(0)
	start := 0
	for {
		end := start + chunkSize
		if end > length {
			end = length
		}
		rows, err := s[start:end].DeleteAll(ctx, exec)
		if err != nil {
			return rowsAffected, err
		}

		rowsAffected += rows
		start = end
		if start >= length {
			break
		}
	}
	return rowsAffected, nil
}

// UpdateAllByPage update all Log records from the slice.
// This function updates data by pages to avoid exceeding Postgres limitation (max parameters: 65535)
func (s LogSlice) UpdateAllByPage(ctx context.Context, exec boil.ContextExecutor, cols M, limits ...int) (int64, error) {
	length := len(s)
	if length == 0 {
		return 0, nil
	}

	// max number of parameters = 65535
	// NOTE: len(cols) should not be too big
	chunkSize := DefaultPageSize
	if len(limits) > 0 && limits[0] > 0 && limits[0] <= MaxPageSize {
		chunkSize = limits[0]
	}
	if length <= chunkSize {
		return s.UpdateAll(ctx, exec, cols)
	}

	rowsAffected := int64(0)
	start := 0
	for {
		end := start + chunkSize
		if end > length {
			end = length
		}
		rows, err := s[start:end].UpdateAll(ctx, exec, cols)
		if err != nil {
			return rowsAffected, err
		}

		rowsAffected += rows
		start = end
		if start >= length {
			break
		}
	}
	return rowsAffected, nil
}

// InsertAllByPage insert all Log records from the slice.
// This function inserts data by pages to avoid exceeding Postgres limitation (max parameters: 65535)
func (s LogSlice) InsertAllByPage(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns, limits ...int) (int64, error) {
	length := len(s)
	if length == 0 {
		return 0, nil
	}

	// max number of parameters = 65535
	chunkSize := MaxPageSize / reflect.ValueOf(&LogColumns).Elem().NumField()
	if len(limits) > 0 && limits[0] > 0 && limits[0] < chunkSize {
		chunkSize = limits[0]
	}
	if length <= chunkSize {
		return s.InsertAll(ctx, exec, columns)
	}

	rowsAffected := int64(0)
	start := 0
	for {
		end := start + chunkSize
		if end > length {
			end = length
		}
		rows, err := s[start:end].InsertAll(ctx, exec, columns)
		if err != nil {
			return rowsAffected, err
		}

		rowsAffected += rows
		start = end
		if start >= length {
			break
		}
	}
	return rowsAffected, nil
}

// InsertIgnoreAllByPage insert all Log records from the slice.
// This function inserts data by pages to avoid exceeding Postgres limitation (max parameters: 65535)
func (s LogSlice) InsertIgnoreAllByPage(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns, limits ...int) (int64, error) {
	length := len(s)
	if length == 0 {
		return 0, nil
	}

	// max number of parameters = 65535
	chunkSize := MaxPageSize / reflect.ValueOf(&LogColumns).Elem().NumField()
	if len(limits) > 0 && limits[0] > 0 && limits[0] < chunkSize {
		chunkSize = limits[0]
	}
	if length <= chunkSize {
		return s.InsertIgnoreAll(ctx, exec, columns)
	}

	rowsAffected := int64(0)
	start := 0
	for {
		end := start + chunkSize
		if end > length {
			end = length
		}
		rows, err := s[start:end].InsertIgnoreAll(ctx, exec, columns)
		if err != nil {
			return rowsAffected, err
		}

		rowsAffected += rows
		start = end
		if start >= length {
			break
		}
	}
	return rowsAffected, nil
}

// UpsertAllByPage upsert all Log records from the slice.
// This function upserts data by pages to avoid exceeding Postgres limitation (max parameters: 65535)
func (s LogSlice) UpsertAllByPage(ctx context.Context, exec boil.ContextExecutor, updateOnConflict bool, conflictColumns []string, updateColumns, insertColumns boil.Columns, limits ...int) (int64, error) {
	length := len(s)
	if length == 0 {
		return 0, nil
	}

	// max number of parameters = 65535
	chunkSize := MaxPageSize / reflect.ValueOf(&LogColumns).Elem().NumField()
	if len(limits) > 0 && limits[0] > 0 && limits[0] < chunkSize {
		chunkSize = limits[0]
	}
	if length <= chunkSize {
		return s.UpsertAll(ctx, exec, updateOnConflict, conflictColumns, updateColumns, insertColumns)
	}

	rowsAffected := int64(0)
	start := 0
	for {
		end := start + chunkSize
		if end > length {
			end = length
		}
		rows, err := s[start:end].UpsertAll(ctx, exec, updateOnConflict, conflictColumns, updateColumns, insertColumns)
		if err != nil {
			return rowsAffected, err
		}

		rowsAffected += rows
		start = end
		if start >= length {
			break
		}
	}
	return rowsAffected, nil
}

// LoadLogClientsByPage performs eager loading of values by page. This is for a N-1 relationship.
func (s LogSlice) LoadLogClientsByPage(ctx context.Context, e boil.ContextExecutor, mods ...qm.QueryMod) error {
	return s.LoadLogClientsByPageEx(ctx, e, DefaultPageSize, mods...)
}
func (s LogSlice) LoadLogClientsByPageEx(ctx context.Context, e boil.ContextExecutor, pageSize int, mods ...qm.QueryMod) error {
	if len(s) == 0 {
		return nil
	}
	for _, chunk := range chunkSlice[*Log](s, pageSize) {
		if err := chunk[0].L.LoadLogClient(ctx, e, false, &chunk, queryMods(mods)); err != nil {
			return err
		}
	}
	return nil
}

func (s LogSlice) GetLoadedLogClients() ClientSlice {
	result := make(ClientSlice, 0, len(s))
	mapCheckDup := make(map[*Client]struct{})
	for _, item := range s {
		if item.R == nil || item.R.LogClient == nil {
			continue
		}
		if _, ok := mapCheckDup[item.R.LogClient]; ok {
			continue
		}
		result = append(result, item.R.LogClient)
		mapCheckDup[item.R.LogClient] = struct{}{}
	}
	return result
}

///////////////////////////////// END EXTENSIONS /////////////////////////////////
